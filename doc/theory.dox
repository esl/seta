/*!
\page theory Theory on Seta

Seta is an efficient work-stealing scheduler. For the class of "fully strict" programs, it achieves space, time, and communication bounds all within a constant factor of optimal.

\section model A model of multithreaded computation

A multithreaded computation can be viewed as a directed acyclic graph. The computation is composed by procedures, each of which is broken into a sequence of threads, which form the vertices of the dag. Each thread is a nonblocking C function, which means that it can run to completion without waiting or suspending once it has been invoked. As one of the threads runs it can spawn a child thread which begins a new procedure. Downward edges connect threads and their procedures with the children they have spawned. A spawn is like a subroutine call, except that the calling thread may execute concurrently with its child, possibly spawning additional children. Since threads cannot block, a thread cannot spawn children and then wait for values to be returned. Rather, the thread must additionally spawn a successor thread to receive the children's return values when they are produced. A thread and its successors are considered to be parts of the same procedure. In the figure, sequences of successor threads that form Cilk procedures are connected by horizontal edges. Return values, and other values sent from one thread to another, induce data dependencies among the threads, where a thread receiving a value cannot begin until another thread sends the value. The thread which is prevented to execute, stalls. Once the producing thread executes, the join dependency is resolved, which enables the consuming thread to resume its execution and become ready.  Data dependencies are shown as upward, curved edges in the figure, called join edges. Thus, a computation unfolds as a spawn tree composed of procedures and the spawn edges that connect them to their children, but the execution is constrained to follow the precedence relation determined by the dag of threads.

When a thread executes a spawn, a new structure, called closure, is allocated in memory for the new thread. Once a thread has been spawned and its closure has been allocated, we say the thread is alive or living. When a thread completes, its related closure is deallocated and the thread dies. An alive thread can be in three difference states namely:
\li ready, if each preceding thread in any path of the dag from the thread root has already executed but the execution of the given thread has not started yet. Note that here the join edges must be taken into account and we need a mechanism to resolve the join dependencies and detect unresolved join dependencies. For this purpose we use a join counter into a closure. During a thread is ready, it lies in the ready queue.
\li executing, if one of the processors is currently executing the instructions of the thread. During a thread is executing, its closure is still allocated but it has removed from the ready queue.
\li stalled, if the thread is still waiting for some his child to send its results back.

According to the described model, the multithread computation is fully strict. Because multithreaded computations with arbitrary dependencies can be impossible to schedule efficiently, we use a subclass of general multithreaded computations in which the kinds of syncrhonizations that can occur are restricted. A strict multithreaded computation is one in wich all join edges from a thread go to an ancestor of the thread in the activation tree. In a strict computation, the only edge into a subtree (emanating from outside the subtree) is the spawn edge that spawns the subtree's root thread. A fully strict computation is one in which all join edges from a thread go to the thread's parent.

A P-processor execution schedule for a multithread computation determines which processors of a P-processor parallel computer execute which instructions at each step. An execution schedule depends on the particular multithreaded computation and the numper P of processors. In any given step of an execution, each processor executes at most one instruction.

The total execution time of a multithreaded computation on a parallel computer with P processors is constrained by two parameters of the computations: the work and the critical path. The work, denoted $T_1$, is the time used by a one-processor execution of the computation, which corresponds to the sum of the execution times of all the threads.
The critical path length, denoted $T_\infty$, is the total amount of time required by an ininite-processor execution, which corresponds to the largest sum of thread execution times along any path in the dag. Consequently the associated path will be a path from the first to the last thread of the dag's root.




\section howwork How Seta work
Each alive thread (executing, ready or stalled) has an associated closure allocated in the heap of a processor. A closure consists of a pointer to the C function that is the thread, a set of arguments as a pointer to a piece of memory of any size allocated and freed by the user at the time of a spawn request, and a join counter indicating the number of missing arguments that need to be supplied before the thread is ready to run. A closure is ready if it has obtained all of its arguments, and it is waiting if some arguments are missing. To run a ready closure, the Sedano scheduler invokes the thread as a procedure using the set of arguments and a context as its arguments. The closure is allocated from a simple runtime heap when it is created, and it is returned to the heap when the thread teminates. The Sedano library supports a data type called continuation which is 

*/
